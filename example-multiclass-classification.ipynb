{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Classifying articles according to topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_document(document, dataset):\n",
    "    \"\"\"\n",
    "    Use the dataset's index to turn our lists of word numbers back into \n",
    "    words\n",
    "    \"\"\"\n",
    "    word_index = dataset.get_word_index()\n",
    "    reverse_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    return \" \".join([reverse_index.get(index - 3, \"?\") for index in document])\n",
    "\n",
    "def vectorise_sequences(sequences, dimension = 10000):\n",
    "    \"\"\"\n",
    "    Return a 'multi-hot' encoding of a sequence of integers\n",
    "    e.g. vectorise_sequences([3,5]) = [0,0,1,0,1,0,0...]\n",
    "    \"\"\"\n",
    "    # Initialise empty results vector\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i,j] = 1.\n",
    "    return results\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    \"\"\"\n",
    "    Convert labels to a one-hot vector\n",
    "    to_one_hot(3) = [0,0,1,0,0,0...]\n",
    "    \"\"\"\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat vectorised training and test sets, and labels\n",
    "x_train = vectorise_sequences(train_data)\n",
    "x_test = vectorise_sequences(test_data)\n",
    "y_train = to_one_hot(train_labels)\n",
    "y_test = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside some values\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 2.6150 - accuracy: 0.5197 - val_loss: 1.7492 - val_accuracy: 0.6350\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4278 - accuracy: 0.7015 - val_loss: 1.2997 - val_accuracy: 0.7200\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.0558 - accuracy: 0.7712 - val_loss: 1.1367 - val_accuracy: 0.7640\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.8315 - accuracy: 0.8249 - val_loss: 1.0254 - val_accuracy: 0.7880\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6684 - accuracy: 0.8572 - val_loss: 0.9587 - val_accuracy: 0.8120\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.8900 - val_loss: 0.9220 - val_accuracy: 0.8170\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4310 - accuracy: 0.9075 - val_loss: 0.8834 - val_accuracy: 0.8250\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3521 - accuracy: 0.9250 - val_loss: 0.9204 - val_accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs = 8,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9946 - accuracy: 0.7809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9945515394210815, 0.7809438705444336]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up a random baseline for this 36 class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/keras-training/example-multiclass-classification.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmachine-learner/home/ubuntu/keras-training/example-multiclass-classification.ipynb#ch0000025vscode-remote?line=2'>3</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(test_labels_copy)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmachine-learner/home/ubuntu/keras-training/example-multiclass-classification.ipynb#ch0000025vscode-remote?line=3'>4</a>\u001b[0m hits_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_labels) \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39marray(test_labels_copy)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmachine-learner/home/ubuntu/keras-training/example-multiclass-classification.ipynb#ch0000025vscode-remote?line=4'>5</a>\u001b[0m hits_array \u001b[39m=\u001b[39m mean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "hits_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? the bank of japan intervened in tokyo to buy dollars just after the market opened dealers said the dollar opened at 142 05 yen against 142 15 25 in new york and 142 50 at the close here yesterday the bank stepped into the market amid selling pressure from interbank dealers dealers said reuter 3'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_document(train_data[5345], reuters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f59de1d4d0accb032b11f8d294187b83046c4a436724d65cf6d639cf7c9051a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
